# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fcptj7NF8pcRbAcnUFX-T9Ud0NXLcMyp
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# Load Data
data = pd.read_csv("player_stats.csv")

# Display Summary
print("Data Summary:\n", data.describe())

# Feature Selection for Clustering
features = ["Goals", "Assists", "PassAccuracy", "Tackles", "Rating"]
X = data[features]

# Normalize
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Optional: Dimensionality Reduction for Visualization
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# Clustering Players into Roles/Types
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X_scaled)
data["Cluster"] = clusters

# Visualize Clusters
plt.figure(figsize=(10, 6))
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=data["Cluster"], palette="Set2")
plt.title("Player Clustering by Performance Metrics")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.grid(True)
plt.show()

# Strategy Optimization: Best XI Selector (Top rating per position)
best_xi = data.sort_values("Rating", ascending=False).groupby("Position").head(1)
print("\nOptimal Starting XI based on Rating:\n", best_xi[["Player", "Position", "Rating"]])

import pandas as pd
import matplotlib.pyplot as plt

# Load data
data = pd.read_csv("player_stats.csv")

# Select Players to Compare
player1 = "Player A"
player2 = "Player B"

# Extract stats for comparison
player1_stats = data[data['Player'] == player1][['Goals', 'Assists', 'PassAccuracy', 'Tackles', 'Rating']].values.flatten()
player2_stats = data[data['Player'] == player2][['Goals', 'Assists', 'PassAccuracy', 'Tackles', 'Rating']].values.flatten()

# Bar plot for comparison
metrics = ['Goals', 'Assists', 'PassAccuracy', 'Tackles', 'Rating']
plt.figure(figsize=(10, 6))
bar_width = 0.35
index = range(len(metrics))

plt.bar(index, player1_stats, bar_width, label=player1)
plt.bar([i + bar_width for i in index], player2_stats, bar_width, label=player2)

plt.xlabel('Metrics')
plt.ylabel('Performance Values')
plt.title(f'Comparison of {player1} and {player2}')
plt.xticks([i + bar_width / 2 for i in index], metrics)
plt.legend()
plt.show()

import pandas as pd
from itertools import combinations

# Load data (Player data with positions and ratings)
data = pd.read_csv("player_stats.csv")

# Define optimal team size (e.g., 11 players for soccer)
optimal_team_size = 11

# Generate all possible combinations of players based on positions
available_players = data[['Player', 'Position', 'Rating']]

# Filter players by positions (e.g., 4 defenders, 3 midfielders, 3 forwards)
defenders = available_players[available_players['Position'] == 'Defender']
midfielders = available_players[available_players['Position'] == 'Midfielder']
forwards = available_players[available_players['Position'] == 'Forward']

# Create combinations for team selection
defender_combos = combinations(defenders['Player'], 4)
midfielder_combos = combinations(midfielders['Player'], 3)
forward_combos = combinations(forwards['Player'], 3)

# Calculate the best team by selecting the highest-rated players for each position
best_team = []
max_rating = 0

# Evaluate all combinations for optimal team selection
for d_combo in defender_combos:
    for m_combo in midfielder_combos:
        for f_combo in forward_combos:
            # Get the ratings of selected players
            selected_players = list(d_combo) + list(m_combo) + list(f_combo)
            selected_players_data = available_players[available_players['Player'].isin(selected_players)]
            team_rating = selected_players_data['Rating'].sum()

            if team_rating > max_rating:
                max_rating = team_rating
                best_team = selected_players

print(f"\nBest Team Based on Ratings: {best_team}")

# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JP6weqlQIbUpBSB8Bxz5_Mg3sPRe9FsT
"""

# Step 1: Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Step 2: Load sample data
data = {
    'Player': ['Alex Smith', 'Jordan Lee', 'Chris Johnson', 'Samir Patel', 'Diego Reyes', 'Marcus Young'],
    'Position': ['Forward', 'Midfielder', 'Defender', 'Midfielder', 'Forward', 'Goalkeeper'],
    'Games Played': [12, 12, 11, 10, 9, 12],
    'Goals': [8, 3, 1, 2, 5, 0],
    'Assists': [3, 5, 1, 6, 2, 0],
    'Pass Accuracy (%)': [84.5, 89.1, 92.0, 86.3, 80.2, 75.0],
    'Distance Covered (km)': [102.3, 95.7, 88.4, 91.2, 78.9, 50.3],
    'Sprints': [34, 28, 20, 25, 30, 2],
    'Yellow Cards': [1, 0, 3, 2, 1, 0],
    'Injuries': [0, 2, 1, 0, 1, 0]
}

df = pd.DataFrame(data)
print(df)

# Step 3: Calculate custom performance metric
# Example: Performance Index = (Goals*4 + Assists*3 + Accuracy*0.5 + Distance*0.2) - (Injuries*5 + Yellow Cards*2)
df['Performance Index'] = (
    df['Goals'] * 4 +
    df['Assists'] * 3 +
    df['Pass Accuracy (%)'] * 0.5 +
    df['Distance Covered (km)'] * 0.2 -
    (df['Injuries'] * 5 + df['Yellow Cards'] * 2)
)

# Step 4: Visualize performance by position
plt.figure(figsize=(10, 6))
sns.barplot(data=df, x='Position', y='Performance Index', errorbar=None)
plt.title("Performance Index by Position")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show

"""# New Section"""

# Install required packages (run in Colab or Jupyter if needed)
!pip install mlxtend pandas

# Step 1: Import Libraries
import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules
import matplotlib.pyplot as plt

# Step 2: Sample Transaction Data
dataset = [
    ['milk', 'bread', 'eggs'],
    ['milk', 'bread'],
    ['milk', 'cookies'],
    ['bread', 'butter'],
    ['milk', 'bread', 'butter', 'eggs'],
    ['cookies', 'butter'],
    ['bread', 'butter'],
    ['milk', 'bread', 'cookies'],
    ['milk', 'eggs'],
    ['bread', 'cookies']
]

# Step 3: Transaction Encoding
te = TransactionEncoder()
te_ary = te.fit(dataset).transform(dataset)
df = pd.DataFrame(te_ary, columns=te.columns_)

# Step 4: Apriori Algorithm to Find Frequent Itemsets
frequent_itemsets = apriori(df, min_support=0.3, use_colnames=True)

# Step 5: Generate Association Rules
rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1.0)

# Step 6: Filter and Display Strong Rules
strong_rules = rules[(rules['confidence'] > 0.6) & (rules['lift'] > 1.2)]
print(strong_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])

# Step 7: Visualize Top 10 Rules by Lift
top10 = strong_rules.sort_values('lift', ascending=False).head(10)
plt.figure(figsize=(10, 6))
plt.barh(range(len(top10)), top10['lift'], color='skyblue')
plt.yticks(range(len(top10)), [f"{list(a)} â†’ {list(c)}" for a, c in zip(top10['antecedents'], top10['consequents'])])
plt.xlabel('Lift')
plt.title('Top 10 Association Rules by Lift')
plt.gca().invert_yaxis()
plt.show()